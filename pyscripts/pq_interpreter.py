# -*- coding: utf-8 -*-
"""PQ_Interpreter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11bhxRCJxnnp63ebyGl36mHV-vc2MdQP_

### **Don't forget to change preprocess_input imports**
"""

import warnings
warnings.filterwarnings('ignore')

import tensorflow as tf
import tensorflow_datasets as tfds

from keras.applications.mobilenet_v3 import preprocess_input

import numpy as np
import pathlib

import time

print(f'TF Version: {tf.__version__}')

"""### Setup"""

# One of these:
# oxford_flowers102, caltech101, oxford_iiit_pet
DATASET = 'oxford_flowers102'

(training_set, validation_set, test_set), ds_info = tfds.load(
    name=DATASET,
    split=['train', 'validation', 'test'],
    with_info=True,
    as_supervised=True
)

BATCH_SIZE=4
AUTOTUNE=tf.data.AUTOTUNE
TRAINING_EPOCHS=10
IMAGE_SIZE=(224, 224)
BUFFER_SIZE=1000
NUM_CLASSES=ds_info.features['label'].num_classes
VERBOSE=0
PREFIX ='MobileNetV3Large'

#TODO: Edit this!
MODEL_DIR = pathlib.Path(f'{pathlib.Path.cwd()}/generated/pq_tflite')

"""### Preparations"""

def resize_image(image, label):
    image = tf.image.resize(image, size=IMAGE_SIZE)
    image = tf.cast(image, dtype = tf.float32)
    image = preprocess_input(image)
    return image, label

# test_data doesn't need to be shuffled
test_set = test_set.map(map_func=resize_image, num_parallel_calls=AUTOTUNE)
test_set = test_set.batch(batch_size=BATCH_SIZE)

def evaluate_tflite(interpreter):
    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]

    predicted_labels = []
    true_labels = []
    for image_batch, label_batch in test_set:
        for index in range(len(label_batch)):
            true_labels.append(label_batch[index].numpy())

        for image in image_batch:
            if input_details['dtype'] == np.uint8:
                input_scale, input_zero_point = input_details["quantization"]
                image = image / input_scale + input_zero_point

            image = np.expand_dims(image, axis=0).astype(input_details["dtype"])
            interpreter.set_tensor(input_details["index"], image)

            interpreter.invoke()

            output = interpreter.get_tensor(output_details["index"])[0]
            prediction = output.argmax()
            predicted_labels.append(prediction)

    accurate_count = 0
    for index in range(len(predicted_labels)):
        if predicted_labels[index] == true_labels[index]:
            accurate_count += 1

    accuracy = accurate_count * 1.0 / len(predicted_labels)

    return accuracy

def get_float16_accuracy(run_num):
  model_path = f'{MODEL_DIR}/PQ_{PREFIX}/run_{run_num}/PQ_{PREFIX}_float16.tflite'
  quant_interpreter = tf.lite.Interpreter(model_path=model_path)
  quant_interpreter.allocate_tensors()
  float_acc = evaluate_tflite(quant_interpreter)

  return float_acc

def get_dynamic_range_accuracy(run_num):
  model_path = f'{MODEL_DIR}/PQ_{PREFIX}/run_{run_num}//PQ_{PREFIX}_dynamic_range.tflite'
  quant_interpreter = tf.lite.Interpreter(model_path=model_path)
  quant_interpreter.allocate_tensors()
  quant_tflite_acc = evaluate_tflite(quant_interpreter)

  return quant_tflite_acc

def get_full_int_accuracy(run_num):
  model_path=f'{MODEL_DIR}/PQ_{PREFIX}/run_{run_num}//PQ_{PREFIX}_full_integer.tflite'
  quant_interpreter = tf.lite.Interpreter(model_path=model_path)
  quant_interpreter.allocate_tensors()
  full_int_accuracy = evaluate_tflite(quant_interpreter)

  return full_int_accuracy

"""### Evaluate and Interpreter Invokes"""

print(f'Results for Post-Training Quantization -- {DATASET} -- {PREFIX}')
for i in range(1, 6):
  print(f'\n--- Evaluating Run {i} ---')

  start_time = time.time()
  float16_acc = get_float16_accuracy(i)
  end_time = time.time()
  elapsed_float = round(end_time - start_time, 2)

  start_time = time.time()
  dynamic_range_acc = get_dynamic_range_accuracy(i)
  end_time = time.time()
  elapsed_dynamic = round(end_time - start_time, 2)

  start_time = time.time()
  full_int_acc = get_full_int_accuracy(i)
  end_time = time.time()
  elapsed_full_int = round(end_time - start_time, 2)

  print(f'Float16 Accuracy      : {round(float16_acc * 100, 2)} in {elapsed_float}s!')
  print(f'Dynamic Range Accuracy: {round(dynamic_range_acc * 100, 2)} in {elapsed_dynamic}s!')
  print(f'Full Int Accuracy     : {round(full_int_acc * 100, 2)} in {elapsed_full_int}s!')
